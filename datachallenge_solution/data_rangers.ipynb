{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Daniel Carvajal Correa** ðŸš€ðŸŽ‘"
      ],
      "metadata": {
        "id": "C47kYEX0O79k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 1: Descarga de archivos\n",
        "\n",
        "En la siguiente celda se encuentra el cÃ³digo para descargar el archivo .zip que contiene los archivos .csv para realizar la prueba. La descarga se realiza a partir del ID que se extrae del URL proporcionado en la guÃ­a.\n",
        "\n",
        "Durante su implementaciÃ³n me encontrÃ© con problemas como:\n",
        "\n",
        "- El nombre del archivo .zip presenta espacios o caracteres tales como parÃ©ntesis que dificultan su manipulaciÃ³n. Para solucionarlo, implementÃ© una funciÃ³n llamada clean_text que se encarga de eliminar este tipo de caracteres en el nombre del archivo y luego realizar su renombramiento.\n",
        "\n",
        "- Al ejecutar unzip cuando la celda ya se habÃ­a ejecutado una vez, se realizaba la peticiÃ³n de renombramiento de archivos nuevamente. Para evitar esto, agreguÃ© un if que verifica si la carpeta ya ha sido extraÃ­da anteriormente."
      ],
      "metadata": {
        "id": "6VEubQJADqOp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cClPKsKJBsKK"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "import re\n",
        "\n",
        "#El id se extrae de la URL enviada en la hoja del test 'https://drive.google.com/file/d/1ejZpGTvZa81ZGD7IRWjObFeVuYbsSvuB/view?usp=sharing'\n",
        "id_file = '1ejZpGTvZa81ZGD7IRWjObFeVuYbsSvuB'\n",
        "!gdown {id_file}\n",
        "\n",
        "def clean_text(text2clean:str) -> str:\n",
        "  text2clean = text2clean.replace(\" \", \"\")\n",
        "  text2clean = re.sub(r'\\([^)]*\\)', '', text2clean)\n",
        "  return text2clean\n",
        "\n",
        "files = os.listdir('/content')\n",
        "for filename in files:\n",
        "  if filename.endswith('.zip'):\n",
        "    new_filename = clean_text(filename)\n",
        "    os.rename(filename, new_filename)\n",
        "    folder_name = new_filename.rsplit('.',1)[0]\n",
        "    if not os.path.exists(folder_name):\n",
        "      !unzip {new_filename}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 2: CreaciÃ³n de la base de datos usando SQLite\n",
        "En las siguientes celdas se hace la creaciÃ³n de la estructura que llevarÃ¡ la base de datos SQLite. Para ello utilicÃ© dos tablas, en una estarÃ¡n los datos en crudo y en la otra estarÃ¡ la parte de estadÃ­sticas analizadas por cada INSERT que se haga."
      ],
      "metadata": {
        "id": "eeCeSamTDwr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "db_con = sqlite3.connect('test_database.db')"
      ],
      "metadata": {
        "id": "pgZ4ne7YEMjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Esta celda crea la tabla donde se guardara la informaciÃ³n de los csvs. \n",
        "with db_con:\n",
        "  db_con.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS data (\n",
        "      id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "      timestamp DATE,\n",
        "      price REAL,\n",
        "      user_id INTEGER\n",
        "    )\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "bS7J9uwcHB8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Esta celda crea la tabla donde se guardara la estadistica de los datos. \n",
        "with db_con:\n",
        "  db_con.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS stats (\n",
        "      element_count INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "      summatory REAL,\n",
        "      average REAL,\n",
        "      max_value REAL,\n",
        "      min_value REAL,\n",
        "      FOREIGN KEY (element_count) REFERENCES data (id)\n",
        "    )\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "k22nRFkRMLcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Guardar cambios\n",
        "db_con.commit()"
      ],
      "metadata": {
        "id": "X3pBiu46P0vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 3: Carga de datos\n",
        "\n",
        "Para preparar la carga de datos, considere crear un patrÃ³n usando expresiÃ³n regular que me permitiera identificar los archivos de tipo: 2012-1.csv y excluir el validation.csv. Como en la guÃ­a dice que puedo asumir que los archivos estÃ¡n correctamente ordenados por fecha, con files.sort() acomodo el orden de los archivos y los subo uno por uno.\n",
        "\n",
        "La funciÃ³n load_csv2db utiliza la declaraciÃ³n 'with open' para abrir el archivo CSV y asegurarse de cerrarlo una vez termine de cargar el CSV. Para leer los datos utilicÃ© pandas y la funciÃ³n read_csv, le ajustÃ© el parÃ¡metro de chunksize en 1 para ir cargando lÃ­nea por lÃ­nea a la base de datos. Esta funciÃ³n tambiÃ©n se apoya en una verificaciÃ³n utilizando booleanos para verificar si el registro en la base de datos fue exitoso. En caso de no ser asÃ­, se realiza un rollback.\n",
        "\n",
        "La funciÃ³n insert_data recibe una lÃ­nea de pandas y la inserta al final en la base de datos. Si existe algÃºn error, devuelve False para realizar un rollback en la base de datos.\n",
        "\n",
        "La funciÃ³n update_stats recibe una lÃ­nea de pandas y recupera la Ãºltima lÃ­nea almacenada en la tabla \"stats\" de la base de datos. Si no se encuentra ninguna lÃ­nea, se inserta la lÃ­nea sin realizar ninguna verificaciÃ³n. En caso de existir previamente una lÃ­nea, se realiza el cÃ¡lculo del promedio utilizando la columna \"sumatoria\" y la columna que tiene el valor de cuÃ¡ntos datos hay almacenados en ese momento. Se verifica si hay alguna novedad en las columnas de \"max\" y \"min\" value, y se inserta la lÃ­nea en la tabla. Si ocurre algÃºn error, devuelve False para realizar un rollback en la base de datos.\n",
        "\n",
        "La funciÃ³n stats2float devuelve las variables en un tipo mÃ¡s manipulable que un DataFrame de pandas."
      ],
      "metadata": {
        "id": "QmKU4kxQnan2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv2db(pathfile:str) -> None:\n",
        "  with open(pathfile) as data: \n",
        "      for minibatch in pd.read_csv(data, chunksize=1):\n",
        "        if minibatch.isnull().values.any():\n",
        "          print('This row will be ignored, there is a Nan value')\n",
        "          print(minibatch)\n",
        "        else:\n",
        "          verify_data = insert_data(minibatch)\n",
        "          verify_stats = update_stats(minibatch)\n",
        "          if verify_data and verify_stats:\n",
        "            db_con.commit()\n",
        "          else:\n",
        "            db_con.rollback()\n",
        "\n",
        "def insert_data(data_rows) -> bool:\n",
        "  try:\n",
        "    data_rows.to_sql('data', db_con, if_exists='append', index=False, index_label=id)\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    print(f'An error ocurred: {e}')\n",
        "    return False\n",
        "\n",
        "def update_stats(data_rows) -> bool:\n",
        "  try:\n",
        "    last_row = pd.read_sql_query(\"SELECT * FROM stats ORDER BY element_count DESC LIMIT 1\", db_con)\n",
        "    insert_stats_query = \"INSERT INTO stats (summatory, average, max_value, min_value) VALUES (?, ?, ?, ?)\"\n",
        "    price = float(data_rows['price'])\n",
        "    if last_row.empty:\n",
        "      with db_con:\n",
        "        values = (price, price, price, price)\n",
        "        db_con.execute(insert_stats_query, values)\n",
        "        print(f'el recuento es:1, el promedio es:{price}, el valor maximo es:{price}, el valor minimo es:{price}') #Este print hace parte de la comprobacion de resultados\n",
        "    else:\n",
        "      element_count, summatory, max_value, min_value = stats2float(last_row)\n",
        "      summatory += price\n",
        "      average = summatory/(element_count + 1)   #el promedio se hace linea por linea utilizando una sumatoria y el numero de elementos guardados en la ultima linea de la tabla stats\n",
        "      if price > max_value:\n",
        "        max_value = price\n",
        "      if price < min_value: \n",
        "        min_value = price\n",
        "      values = (summatory, average, max_value, min_value)\n",
        "      db_con.execute(insert_stats_query, values)\n",
        "      print(f'el recuento es:{element_count + 1}, el promedio es:{average}, el valor maximo es:{max_value}, el valor minimo es:{min_value}') #Este print hace parte de la comprobacion de resultados\n",
        "      return True\n",
        "  except Exception as e:\n",
        "    print(f'An error ocurred: {e}')\n",
        "    return False\n",
        "    \n",
        "\n",
        "def stats2float(data_row):\n",
        "  element_count = int(data_row['element_count'])\n",
        "  summatory = float(data_row['summatory'])\n",
        "  max_value = float(data_row['max_value'])\n",
        "  min_value = float(data_row['min_value'])\n",
        "  return element_count, summatory, max_value, min_value\n"
      ],
      "metadata": {
        "id": "Cp3r5fuZSdIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_filename_pattern = re.compile(r'[0-9]+-[0-9]+\\.[A-Za-z]+', re.IGNORECASE)\n",
        "path2files = f'/content/{folder_name}'\n",
        "files = os.listdir(path2files)\n",
        "files.sort()\n",
        "for file in files:\n",
        "  if csv_filename_pattern.match(file):\n",
        "    load_csv2db(f'{path2files}/{file}')\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "4f5QV3QInYum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPROBACIÃ“N DE RESULTADOS:\n",
        "\n",
        "**Imprime el valor actual de las estadÃ­sticas en ejecuciÃ³n.**\n",
        "El primer item de la comprobacion de resultados se muestra con un print en la celda anterior. En donde a medida que va integrando lineas a la base de datos va haciendo un recuento de las estadisticas requeridas."
      ],
      "metadata": {
        "id": "B_2RW8QMhxIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Realiza una consulta en la base de datos del: recuento total de filas, valor promedio, valor mÃ­nimo y valor mÃ¡ximo para el campo â€œpriceâ€.\n",
        "with db_con:\n",
        "  verification_query = db_con.execute(\"SELECT COUNT(price), AVG(price), MAX(price), MIN(price) FROM data\")\n",
        "  results = verification_query.fetchone()\n",
        "  print(f'el recuento es:{results[0]}, el promedio es:{results[1]}, el valor maximo es:{results[2]}, el valor minimo es:{results[3]}') \n",
        "\n"
      ],
      "metadata": {
        "id": "wrq4w38miPEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Ejecuta el archivo â€œvalidation.csvâ€ a travÃ©s de todo el pipeline y muestra el valor de las estadÃ­sticas en ejecuciÃ³n.\n",
        "\n",
        "load_csv2db('/content/dataPruebaDataEngineer/validation.csv')"
      ],
      "metadata": {
        "id": "DldOQ8tMjlrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Realice una nueva consulta en la base de datos despuÃ©s de cargar â€œvalidation.csvâ€, para observar cÃ³mo cambiaron los valores del: recuento total de filas, valor promedio, valor mÃ­nimo y valor mÃ¡ximo para el campo â€œpriceâ€.\n",
        "with db_con:\n",
        "  verification_query = db_con.execute(\"SELECT COUNT(price), AVG(price), MAX(price), MIN(price) FROM data\")\n",
        "  results = verification_query.fetchone()\n",
        "  print(f'el recuento es:{results[0]}, el promedio es:{results[1]}, el valor maximo es:{results[2]}, el valor minimo es:{results[3]}') "
      ],
      "metadata": {
        "id": "n6MAaEPSkFHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VISUALIZACIÃ“N DE LOS DATOS"
      ],
      "metadata": {
        "id": "kaiWt8Oby89Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "stats_frame = pd.read_sql_query(\"SELECT * FROM stats\", db_con)\n",
        "data_frame = pd.read_sql_query(\"SELECT * FROM data\", db_con)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(stats_frame['element_count'], stats_frame['average'], label='promedio')\n",
        "ax.plot(stats_frame['element_count'], stats_frame['max_value'], label='valor maximo')\n",
        "ax.plot(stats_frame['element_count'], stats_frame['min_value'], label='valor minimo')\n",
        "ax.scatter(stats_frame['element_count'], data_frame['price'], color='red', marker='o', s=10, label='precio de cada elemento')\n",
        "\n",
        "ax.set_xlabel('Numero de elementos agregados')\n",
        "ax.set_ylabel('Precio')\n",
        "ax.legend(loc='lower right')\n",
        "plt.title('Grafica de promedio, maximo valor y minimo valor con relacion a cada elementro ingresado')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "WQYmcHQfzAWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELDAS DE UTILIDADES\n",
        "las celdas de este apartado se crearon para realizar pruebas durante la creacion de este notebook, ignorar en su ejecucion."
      ],
      "metadata": {
        "id": "sPYNMMuZXgGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#celda creada para la visualizacion de la db facilmente\n",
        "query = 'SELECT * FROM data'\n",
        "df = pd.read_sql_query(query, db_con)\n",
        "print(df)\n",
        "\n",
        "query = 'SELECT * FROM stats'\n",
        "df = pd.read_sql_query(query, db_con)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "xo2EahCBNxZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Celda creada para eliminar las tablas y hacer pruebas de nuevo\n",
        "with db_con:\n",
        "  db_con.execute(\"DROP TABLE IF EXISTS data\")\n",
        "  db_con.execute(\"DROP TABLE IF EXISTS stats\")\n",
        "db_con.commit()"
      ],
      "metadata": {
        "id": "4rcDw0rJV-xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Celda para exportar tablas a csv\n",
        "import csv\n",
        "cursor = db_con.cursor()\n",
        "cursor.execute(\"SELECT * FROM stats\")\n",
        "\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "csv_file = \"output.csv\"\n",
        "\n",
        "with open(csv_file, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([i[0] for i in cursor.description])\n",
        "    writer.writerows(rows)"
      ],
      "metadata": {
        "id": "3vjG811kcD2I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}