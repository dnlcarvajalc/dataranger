{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Daniel Carvajal Correa** 🚀🎑"
      ],
      "metadata": {
        "id": "C47kYEX0O79k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 1: Descarga de archivos\n",
        "\n",
        "En la siguiente celda se encuentra el código para descargar el archivo .zip que contiene los archivos .csv para realizar la prueba. La descarga se realiza a partir del ID que se extrae del URL proporcionado en la guía.\n",
        "\n",
        "Durante su implementación me encontré con problemas como:\n",
        "\n",
        "- El nombre del archivo .zip presenta espacios o caracteres tales como paréntesis que dificultan su manipulación. Para solucionarlo, implementé una función llamada clean_text que se encarga de eliminar este tipo de caracteres en el nombre del archivo y luego realizar su renombramiento.\n",
        "\n",
        "- Al ejecutar unzip cuando la celda ya se había ejecutado una vez, se realizaba la petición de renombramiento de archivos nuevamente. Para evitar esto, agregué un if que verifica si la carpeta ya ha sido extraída anteriormente."
      ],
      "metadata": {
        "id": "6VEubQJADqOp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cClPKsKJBsKK"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "import re\n",
        "\n",
        "#El id se extrae de la URL enviada en la hoja del test 'https://drive.google.com/file/d/1ejZpGTvZa81ZGD7IRWjObFeVuYbsSvuB/view?usp=sharing'\n",
        "id_file = '1ejZpGTvZa81ZGD7IRWjObFeVuYbsSvuB'\n",
        "!gdown {id_file}\n",
        "\n",
        "def clean_text(text2clean:str) -> str:\n",
        "  text2clean = text2clean.replace(\" \", \"\")\n",
        "  text2clean = re.sub(r'\\([^)]*\\)', '', text2clean)\n",
        "  return text2clean\n",
        "\n",
        "files = os.listdir('/content')\n",
        "for filename in files:\n",
        "  if filename.endswith('.zip'):\n",
        "    new_filename = clean_text(filename)\n",
        "    os.rename(filename, new_filename)\n",
        "    folder_name = new_filename.rsplit('.',1)[0]\n",
        "    if not os.path.exists(folder_name):\n",
        "      !unzip {new_filename}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 2: Creación de la base de datos usando SQLite\n",
        "En las siguientes celdas se hace la creación de la estructura que llevará la base de datos SQLite. Para ello utilicé dos tablas, en una estarán los datos en crudo y en la otra estará la parte de estadísticas analizadas por cada INSERT que se haga."
      ],
      "metadata": {
        "id": "eeCeSamTDwr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "db_con = sqlite3.connect('test_database.db')"
      ],
      "metadata": {
        "id": "pgZ4ne7YEMjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Esta celda crea la tabla donde se guardara la información de los csvs. \n",
        "with db_con:\n",
        "  db_con.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS data (\n",
        "      id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "      timestamp DATE,\n",
        "      price REAL,\n",
        "      user_id INTEGER\n",
        "    )\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "bS7J9uwcHB8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Esta celda crea la tabla donde se guardara la estadistica de los datos. \n",
        "with db_con:\n",
        "  db_con.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS stats (\n",
        "      element_count INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "      summatory REAL,\n",
        "      average REAL,\n",
        "      max_value REAL,\n",
        "      min_value REAL,\n",
        "      FOREIGN KEY (element_count) REFERENCES data (id)\n",
        "    )\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "k22nRFkRMLcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Guardar cambios\n",
        "db_con.commit()"
      ],
      "metadata": {
        "id": "X3pBiu46P0vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 3: Carga de datos\n",
        "\n",
        "Para preparar la carga de datos, considere crear un patrón usando expresión regular que me permitiera identificar los archivos de tipo: 2012-1.csv y excluir el validation.csv. Como en la guía dice que puedo asumir que los archivos están correctamente ordenados por fecha, con files.sort() acomodo el orden de los archivos y los subo uno por uno.\n",
        "\n",
        "La función load_csv2db utiliza la declaración 'with open' para abrir el archivo CSV y asegurarse de cerrarlo una vez termine de cargar el CSV. Para leer los datos utilicé pandas y la función read_csv, le ajusté el parámetro de chunksize en 1 para ir cargando línea por línea a la base de datos. Esta función también se apoya en una verificación utilizando booleanos para verificar si el registro en la base de datos fue exitoso. En caso de no ser así, se realiza un rollback.\n",
        "\n",
        "La función insert_data recibe una línea de pandas y la inserta al final en la base de datos. Si existe algún error, devuelve False para realizar un rollback en la base de datos.\n",
        "\n",
        "La función update_stats recibe una línea de pandas y recupera la última línea almacenada en la tabla \"stats\" de la base de datos. Si no se encuentra ninguna línea, se inserta la línea sin realizar ninguna verificación. En caso de existir previamente una línea, se realiza el cálculo del promedio utilizando la columna \"sumatoria\" y la columna que tiene el valor de cuántos datos hay almacenados en ese momento. Se verifica si hay alguna novedad en las columnas de \"max\" y \"min\" value, y se inserta la línea en la tabla. Si ocurre algún error, devuelve False para realizar un rollback en la base de datos.\n",
        "\n",
        "La función stats2float devuelve las variables en un tipo más manipulable que un DataFrame de pandas."
      ],
      "metadata": {
        "id": "QmKU4kxQnan2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv2db(pathfile:str) -> None:\n",
        "  with open(pathfile) as data: \n",
        "      for minibatch in pd.read_csv(data, chunksize=1):\n",
        "        if minibatch.isnull().values.any():\n",
        "          print('This row will be ignored, there is a Nan value')\n",
        "          print(minibatch)\n",
        "        else:\n",
        "          verify_data = insert_data(minibatch)\n",
        "          verify_stats = update_stats(minibatch)\n",
        "          if verify_data and verify_stats:\n",
        "            db_con.commit()\n",
        "          else:\n",
        "            db_con.rollback()\n",
        "\n",
        "def insert_data(data_rows) -> bool:\n",
        "  try:\n",
        "    data_rows.to_sql('data', db_con, if_exists='append', index=False, index_label=id)\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    print(f'An error ocurred: {e}')\n",
        "    return False\n",
        "\n",
        "def update_stats(data_rows) -> bool:\n",
        "  try:\n",
        "    last_row = pd.read_sql_query(\"SELECT * FROM stats ORDER BY element_count DESC LIMIT 1\", db_con)\n",
        "    insert_stats_query = \"INSERT INTO stats (summatory, average, max_value, min_value) VALUES (?, ?, ?, ?)\"\n",
        "    price = float(data_rows['price'])\n",
        "    if last_row.empty:\n",
        "      with db_con:\n",
        "        values = (price, price, price, price)\n",
        "        db_con.execute(insert_stats_query, values)\n",
        "        print(f'el recuento es:1, el promedio es:{price}, el valor maximo es:{price}, el valor minimo es:{price}') #Este print hace parte de la comprobacion de resultados\n",
        "    else:\n",
        "      element_count, summatory, max_value, min_value = stats2float(last_row)\n",
        "      summatory += price\n",
        "      average = summatory/(element_count + 1)   #el promedio se hace linea por linea utilizando una sumatoria y el numero de elementos guardados en la ultima linea de la tabla stats\n",
        "      if price > max_value:\n",
        "        max_value = price\n",
        "      if price < min_value: \n",
        "        min_value = price\n",
        "      values = (summatory, average, max_value, min_value)\n",
        "      db_con.execute(insert_stats_query, values)\n",
        "      print(f'el recuento es:{element_count + 1}, el promedio es:{average}, el valor maximo es:{max_value}, el valor minimo es:{min_value}') #Este print hace parte de la comprobacion de resultados\n",
        "      return True\n",
        "  except Exception as e:\n",
        "    print(f'An error ocurred: {e}')\n",
        "    return False\n",
        "    \n",
        "\n",
        "def stats2float(data_row):\n",
        "  element_count = int(data_row['element_count'])\n",
        "  summatory = float(data_row['summatory'])\n",
        "  max_value = float(data_row['max_value'])\n",
        "  min_value = float(data_row['min_value'])\n",
        "  return element_count, summatory, max_value, min_value\n"
      ],
      "metadata": {
        "id": "Cp3r5fuZSdIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_filename_pattern = re.compile(r'[0-9]+-[0-9]+\\.[A-Za-z]+', re.IGNORECASE)\n",
        "path2files = f'/content/{folder_name}'\n",
        "files = os.listdir(path2files)\n",
        "files.sort()\n",
        "for file in files:\n",
        "  if csv_filename_pattern.match(file):\n",
        "    load_csv2db(f'{path2files}/{file}')\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "4f5QV3QInYum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPROBACIÓN DE RESULTADOS:\n",
        "\n",
        "**Imprime el valor actual de las estadísticas en ejecución.**\n",
        "El primer item de la comprobacion de resultados se muestra con un print en la celda anterior. En donde a medida que va integrando lineas a la base de datos va haciendo un recuento de las estadisticas requeridas."
      ],
      "metadata": {
        "id": "B_2RW8QMhxIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Realiza una consulta en la base de datos del: recuento total de filas, valor promedio, valor mínimo y valor máximo para el campo “price”.\n",
        "with db_con:\n",
        "  verification_query = db_con.execute(\"SELECT COUNT(price), AVG(price), MAX(price), MIN(price) FROM data\")\n",
        "  results = verification_query.fetchone()\n",
        "  print(f'el recuento es:{results[0]}, el promedio es:{results[1]}, el valor maximo es:{results[2]}, el valor minimo es:{results[3]}') \n",
        "\n"
      ],
      "metadata": {
        "id": "wrq4w38miPEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Ejecuta el archivo “validation.csv” a través de todo el pipeline y muestra el valor de las estadísticas en ejecución.\n",
        "\n",
        "load_csv2db('/content/dataPruebaDataEngineer/validation.csv')"
      ],
      "metadata": {
        "id": "DldOQ8tMjlrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Realice una nueva consulta en la base de datos después de cargar “validation.csv”, para observar cómo cambiaron los valores del: recuento total de filas, valor promedio, valor mínimo y valor máximo para el campo “price”.\n",
        "with db_con:\n",
        "  verification_query = db_con.execute(\"SELECT COUNT(price), AVG(price), MAX(price), MIN(price) FROM data\")\n",
        "  results = verification_query.fetchone()\n",
        "  print(f'el recuento es:{results[0]}, el promedio es:{results[1]}, el valor maximo es:{results[2]}, el valor minimo es:{results[3]}') "
      ],
      "metadata": {
        "id": "n6MAaEPSkFHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VISUALIZACIÓN DE LOS DATOS"
      ],
      "metadata": {
        "id": "kaiWt8Oby89Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "stats_frame = pd.read_sql_query(\"SELECT * FROM stats\", db_con)\n",
        "data_frame = pd.read_sql_query(\"SELECT * FROM data\", db_con)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(stats_frame['element_count'], stats_frame['average'], label='promedio')\n",
        "ax.plot(stats_frame['element_count'], stats_frame['max_value'], label='valor maximo')\n",
        "ax.plot(stats_frame['element_count'], stats_frame['min_value'], label='valor minimo')\n",
        "ax.scatter(stats_frame['element_count'], data_frame['price'], color='red', marker='o', s=10, label='precio de cada elemento')\n",
        "\n",
        "ax.set_xlabel('Numero de elementos agregados')\n",
        "ax.set_ylabel('Precio')\n",
        "ax.legend(loc='lower right')\n",
        "plt.title('Grafica de promedio, maximo valor y minimo valor con relacion a cada elementro ingresado')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "WQYmcHQfzAWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELDAS DE UTILIDADES\n",
        "las celdas de este apartado se crearon para realizar pruebas durante la creacion de este notebook, ignorar en su ejecucion."
      ],
      "metadata": {
        "id": "sPYNMMuZXgGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#celda creada para la visualizacion de la db facilmente\n",
        "query = 'SELECT * FROM data'\n",
        "df = pd.read_sql_query(query, db_con)\n",
        "print(df)\n",
        "\n",
        "query = 'SELECT * FROM stats'\n",
        "df = pd.read_sql_query(query, db_con)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "xo2EahCBNxZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Celda creada para eliminar las tablas y hacer pruebas de nuevo\n",
        "with db_con:\n",
        "  db_con.execute(\"DROP TABLE IF EXISTS data\")\n",
        "  db_con.execute(\"DROP TABLE IF EXISTS stats\")\n",
        "db_con.commit()"
      ],
      "metadata": {
        "id": "4rcDw0rJV-xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Celda para exportar tablas a csv\n",
        "import csv\n",
        "cursor = db_con.cursor()\n",
        "cursor.execute(\"SELECT * FROM stats\")\n",
        "\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "csv_file = \"output.csv\"\n",
        "\n",
        "with open(csv_file, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([i[0] for i in cursor.description])\n",
        "    writer.writerows(rows)"
      ],
      "metadata": {
        "id": "3vjG811kcD2I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}